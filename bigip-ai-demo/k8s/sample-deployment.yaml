# Namespace Definition.
# ========================
# Nginx ConfigMap for AI Cluster
# ========================
apiVersion: v1
kind: ConfigMap
metadata:
  name: ai-cluster-nginx-config
  namespace: bigip-demo
data:
  default.conf: |
    server {
        listen 8080;
        server_name localhost;
        location / {
            root /usr/share/nginx/html;
            index index.html;
        }
    }

---

apiVersion: v1
kind: Namespace
metadata:
  name: bigip-demo
--- 
apiVersion: security.openshift.io/v1
kind: SecurityContextConstraints
metadata:
  name: ai-agent-scc
allowPrivilegedContainer: false
allowHostDirVolumePlugin: false
allowHostIPC: false
allowHostNetwork: false
allowHostPID: false
allowHostPorts: false
allowPrivilegeEscalation: false
defaultAddCapabilities: []
fsGroup:
  type: MustRunAs
  ranges:
    - min: 1000900000
      max: 1000909999
readOnlyRootFilesystem: false
requiredDropCapabilities:
  - ALL
runAsUser:
  type: MustRunAs
  uid: 1000900000  # OpenShift-compatible UID
seLinuxContext:
  type: MustRunAs
seccompProfiles:
  - runtime/default
supplementalGroups:
  type: RunAsAny
volumes:
  - configMap
  - downwardAPI
  - emptyDir
  - persistentVolumeClaim
  - projected
  - secret
users:
  - system:serviceaccount:bigip-demo:ai-agent
---
# AI Cluster Deployment - simulating external AI workload traffic.
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-cluster
  namespace: bigip-demo
  labels:
    app: ai-cluster
    role: ai
spec:
  replicas: 3
  selector:
    matchLabels:
      app: ai-cluster
  template:
    metadata:
      labels:
        app: ai-cluster
        role: ai
    spec:
      serviceAccountName: ai-agent
      securityContext:
          runAsNonRoot: true
          seccompProfile:
            type: RuntimeDefault
      containers:
      - name: ai-cluster-container
        image: nginx:stable
        command: ["/bin/sh", "-c", "sed -i 's/listen 80;/listen 8080;/' /etc/nginx/conf.d/default.conf && exec nginx -g 'daemon off;'"]
        securityContext:
          runAsUser: 1000900000 
          runAsNonRoot: true  
          capabilities:
            drop: ["ALL"]  
          allowPrivilegeEscalation: false  
          seccompProfile:
            type: RuntimeDefault
        resources:
          requests:
            cpu: "200m"
            memory: "256Mi"
          limits:
            cpu: "500m"
            memory: "512Mi"
        ports:
        - containerPort: 8080
        volumeMounts:
        - name: nginx-cache
          mountPath: /var/cache/nginx
        - name: nginx-tmp
          mountPath: /tmp
        - name: nginx-config
          mountPath: /etc/nginx/conf.d/default.conf
          subPath: default.conf
      volumes:
      - name: nginx-config
        configMap:
          name: ai-cluster-nginx-config
      - name: nginx-cache
        emptyDir: {}
      - name: nginx-tmp
        emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: ai-cluster-service
  namespace: bigip-demo
  labels:
    app: ai-cluster
spec:
  selector:
    app: ai-cluster
  ports:
  - name: http
    port: 8080
    targetPort: 8080
  type: ClusterIP
---
# East-West Deployment - for internal AI/RAG workflows.
apiVersion: apps/v1
kind: Deployment
metadata:
  name: eastwest-app
  namespace: bigip-demo
  labels:
    app: eastwest
    role: internal
spec:
  replicas: 2
  selector:
    matchLabels:
      app: eastwest
  template:
    metadata:
      labels:
        app: eastwest
        role: internal
    spec:
      serviceAccountName: ai-agent
      securityContext:
          runAsNonRoot: true
          seccompProfile:
            type: RuntimeDefault
      containers:
      - name: eastwest-container
        image: nginx:stable
        command: ["/bin/sh", "-c", "sed -i 's/listen 80;/listen 8080;/' /etc/nginx/conf.d/default.conf && exec nginx -g 'daemon off;'"]
        securityContext:
          runAsUser: 1000900000   # Run as non-root user 
          capabilities:
            drop: ["ALL"]  
          allowPrivilegeEscalation: false  
          seccompProfile:
            type: RuntimeDefault
        resources:
          requests:
            cpu: "100m"
            memory: "128Mi"
          limits:
            cpu: "300m"
            memory: "256Mi"
        ports:
        - containerPort: 8080
        volumeMounts:
        - name: nginx-cache
          mountPath: /var/cache/nginx
        - name: nginx-tmp
          mountPath: /tmp
        - name: nginx-config
          mountPath: /etc/nginx/conf.d/default.conf
          subPath: default.conf
      volumes:
      - name: nginx-config
        configMap:
          name: ai-cluster-nginx-config
      - name: nginx-cache
        emptyDir: {}
      - name: nginx-tmp
        emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: eastwest-service
  namespace: bigip-demo
  labels:
    app: eastwest
spec:
  selector:
    app: eastwest
  ports:
  - name: http
    port: 8080
    targetPort: 8080
  type: ClusterIP
---
# Storage Service Deployment - simulating data storage traffic.
apiVersion: apps/v1
kind: Deployment
metadata:
  name: storage-service
  namespace: bigip-demo
  labels:
    app: storage-service
    role: storage
spec:
  replicas: 2
  selector:
    matchLabels:
      app: storage-service
  template:
    metadata:
      labels:
        app: storage-service
        role: storage
    spec:
      containers:
      - name: minio
        image: minio/minio:latest
        args:
          - "server"
          - "/data"
        env:
          - name: MINIO_ACCESS_KEY
            value: "minioaccess"
          - name: MINIO_SECRET_KEY
            value: "miniosecret"
        ports:
        - containerPort: 9000
        volumeMounts:
        - name: storage-data
          mountPath: /data
      volumes:
      - name: storage-data
        emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: storage-service
  namespace: bigip-demo
  labels:
    app: storage-service
spec:
  selector:
    app: storage-service
  ports:
  - name: http
    port: 9000
    targetPort: 9000
  type: ClusterIP
---
# Multi-Cluster Networking Deployment - simulating global load balancing.
apiVersion: apps/v1
kind: Deployment
metadata:
  name: multicluster-service
  namespace: bigip-demo
  labels:
    app: multicluster
    role: global
spec:
  replicas: 2
  selector:
    matchLabels:
      app: multicluster
  template:
    metadata:
      labels:
        app: multicluster
        role: global
    spec:
      serviceAccountName: ai-agent
      securityContext:
          runAsNonRoot: true
          seccompProfile:
            type: RuntimeDefault
      containers:
      - name: multicluster-container
        image: nginx:stable
        command: ["/bin/sh", "-c", "sed -i 's/listen 80;/listen 8080;/' /etc/nginx/conf.d/default.conf && exec nginx -g 'daemon off;'"]
        securityContext:
          runAsUser: 1000900000  # Run as non-root user
          capabilities:
            drop: ["ALL"]  
          allowPrivilegeEscalation: false  
          seccompProfile:
            type: RuntimeDefault
        resources:
          requests:
            cpu: "150m"
            memory: "200Mi"
          limits:
            cpu: "400m"
            memory: "400Mi"
        ports:
        - containerPort: 8080
        volumeMounts:
        - name: nginx-cache
          mountPath: /var/cache/nginx
        - name: nginx-tmp
          mountPath: /tmp
        - name: nginx-config
          mountPath: /etc/nginx/conf.d/default.conf
          subPath: default.conf
      volumes:
      - name: nginx-config
        configMap:
          name: ai-cluster-nginx-config
      - name: nginx-cache
        emptyDir: {}
      - name: nginx-tmp
        emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: multicluster-service
  namespace: bigip-demo
  labels:
    app: multicluster
spec:
  selector:
    app: multicluster
  ports:
  - name: http
    port: 8080
    targetPort: 8080
  type: ClusterIP
---
# Low Latency Deployment - optimized for high performance.
apiVersion: apps/v1
kind: Deployment
metadata:
  name: lowlatency-app
  namespace: bigip-demo
  labels:
    app: lowlatency
    role: performance
spec:
  replicas: 2
  selector:
    matchLabels:
      app: lowlatency
  template:
    metadata:
      labels:
        app: lowlatency
        role: performance
    spec:
      serviceAccountName: ai-agent
      securityContext:
          runAsNonRoot: true
          seccompProfile:
            type: RuntimeDefault 
      containers:
      - name: lowlatency-container
        image: nginx:stable
        command: ["/bin/sh", "-c", "sed -i 's/listen 80;/listen 8080;/' /etc/nginx/conf.d/default.conf && exec nginx -g 'daemon off;'"]
        securityContext:
          runAsUser: 1000900000
          capabilities:
            drop: ["ALL"]  
          allowPrivilegeEscalation: false  
          seccompProfile:
            type: RuntimeDefault
        resources:
          requests:
            cpu: "50m"
            memory: "64Mi"
          limits:
            cpu: "150m"
            memory: "128Mi"
        ports:
        - containerPort: 8080
        volumeMounts:
        - name: nginx-cache
          mountPath: /var/cache/nginx
        - name: nginx-tmp
          mountPath: /tmp
        - name: nginx-config
          mountPath: /etc/nginx/conf.d/default.conf
          subPath: default.conf
      volumes:
      - name: nginx-config
        configMap:
          name: ai-cluster-nginx-config
      - name: nginx-cache
        emptyDir: {}
      - name: nginx-tmp
        emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: lowlatency-service
  namespace: bigip-demo
  labels:
    app: lowlatency
spec:
  selector:
    app: lowlatency
  ports:
  - name: http
    port: 8080
    targetPort: 8080
  type: ClusterIP
---
# AI Workload Simulator - simulating AI inference traffic.
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-workload-sim
  namespace: bigip-demo
  labels:
    app: ai-workload
    role: ai-simulator
spec:
  replicas: 2
  selector:
    matchLabels:
      app: ai-workload
  template:
    metadata:
      labels:
        app: ai-workload
        role: ai-simulator
    spec:
      containers:
      - name: ai-workload-sim-container
        image: quay.io/trinathsquay/ai-workload-sim:latest
        resources:
          requests:
            cpu: "100m"
            memory: "128Mi"
          limits:
            cpu: "300m"
            memory: "256Mi"
        ports:
        - containerPort: 8080
---
apiVersion: v1
kind: Service
metadata:
  name: ai-workload-service
  namespace: bigip-demo
  labels:
    app: ai-workload
spec:
  selector:
    app: ai-workload
  ports:
  - name: http
    port: 8080
    targetPort: 8080
  type: ClusterIP


---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: ai-agent
  namespace: bigip-demo
